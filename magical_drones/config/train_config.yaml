trainer:
  max_epochs: 100
  precision: "bf16-true"
  # accumulate_grad_batches: 4 can't use grad_accumulation with manual optimizers
  # val_check_interval: 1000
  limit_val_batches: 0.25
  benchmark: true
model:
  lr: 0.00005
  # lambda_cycle: 10
  lambda_l1: 30
  num_features: 64
  num_residuals: 9
  depth: 4
data:
  data_link: "czarna-magia/mag-map"
  batch_size: 50
  num_workers: 12
  train_tfms:
    size: 256
    degrees: 10
    translate: [0.05, 0.05]
    scale: [0.9, 1.2]
    shear: [-5, 5, -5, 5]
  valid_tfms:
    size: 256
  test_tfms:
    size: 256

other:
  use_TF32: true
  checkpoint_interval: 500